{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import request as req\n",
    "\n",
    "data_dir = '/Users/ssv/newprolab/project01'\n",
    "filename = 'gender_age_dataset.txt'\n",
    "file_path = '/'.join([data_dir, filename])\n",
    "url = 'http://data.newprolab.com/data-newprolab-com/project01/' + filename\n",
    "\n",
    "# req.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Оцифровка значений пола и возраста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ages = {'18-24': 1, '25-34': 2, '35-44': 3, '45-54': 4, '>=55': 5}\n",
    "df[\"age\"] = df[\"age\"].apply(lambda x: ages.get(x, '-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genders = {'M': 1, 'F': 0}\n",
    "df[\"gender\"] = df[\"gender\"].apply(lambda x: genders.get(x, '-'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Формирование набора данных с ключевыми словами посещенных сайтов\n",
    "\n",
    "#### Загружаем из файлов типа df_med_keywords_0000_0999.pickle по мере поступления. Скрапинг сайтов идет очень медленно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/keywords_999.pickle', 'rb') as file:\n",
    "    df_med_keywords_0000_0999 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/keywords_2000_6999.pickle', 'rb') as file:\n",
    "    df_med_keywords_2000_6999 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/df_med_keywords_non_age.pickle', 'rb') as file:\n",
    "    df_for_pred = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удаляем лишние столбцы в наборе данных после скрапинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_keywords_0000_0999 = df_med_keywords_0000_0999.drop('url_netloc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_med_keywords_2000_6999 = df_med_keywords_2000_6999.drop('url_netloc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_pred = df_for_pred.drop(['url_netloc', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Соединяем загруженные таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k = pd.merge(df_med_keywords_0000_0999, pd.merge(df_med_keywords_2000_6999, df_for_pred, how='left', on='uid'),\n",
    "              how='left', on='uid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сводим ключевые слова в один столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42d2c60c22b4108a11bb0307297be09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['keywords'] = ''\n",
    "for index, row in tqdm_notebook(df_k.iterrows()):\n",
    "    if index < 1000:\n",
    "        df_k['raw_keywords'].loc[index] = df_k['raw_keywords'].iloc[index]\n",
    "    if index >= 2000 and index < 7000:\n",
    "        df_k['raw_keywords'].loc[index] = df_k['raw_keywords_x'].iloc[index]\n",
    "    if index > 36137:    \n",
    "        df_k['raw_keywords'].loc[index] = df_k['raw_keywords_y'].iloc[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Левое последовательное соединение таблиц по uid. Удаляем лишние столбцы после соединения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_k = df_k.drop(['raw_keywords_x', 'raw_keywords_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_k, how='left', on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user_json', 'keywords'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  В результате - имеем набор df['gender', 'age', 'uid', 'raw_keywords']. Ключевые слова посещенных сайтов заполнены для строк 0 - 999; 2000 - 6999 и таргет: 36138 - 41137. В заполненных строках есть пустые значения (массив длиной 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Вытащим все ключевые слова для формирования массива стоп-слов\n",
    "2. Разобьем датасет на два фолда: для тренировки (0000 - 36137) и предсказания (36138 - 41137)\n",
    "3. Из фолдов удалим строки в которых нет ключевых слов сайтов\n",
    "4. Сохраняем таргеты и тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_words = list(df['raw_keywords'].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7deb901594544622b91db52fdf830954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm_notebook(reversed(raw_words)):\n",
    "    if len(item) == 0:\n",
    "        raw_words.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "m = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "GROUPING_SPACE_REGEX = re.compile(r'([^\\w]|[+])', re.UNICODE)\n",
    "\n",
    "def simple_word_tokenize(text, _split=GROUPING_SPACE_REGEX.split):\n",
    "    return [t for t in _split(text.lower()) if t and not t.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def token_r(text):\n",
    "    words = simple_word_tokenize(text)\n",
    "    return [m.parse(x)[0].normal_form for x in words if len(x) >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_words = [' '.join((x)) for x in raw_words]\n",
    "clear_words = [' '.join(token_r(x)) for x in raw_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('data/clear_words.pickle', 'wb') as file:\n",
    "#     pickle.dump(clear_words, file) \n",
    "    \n",
    "# with open('data/clear_words.pickle', 'rb') as file:\n",
    "#     clear_words = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "matrix = cv.fit_transform(clear_words)\n",
    "stop_ww = sorted(cv.vocabulary_.items(), reverse=True)[:552] + sorted(cv.vocabulary_.items())[:1451]\n",
    "stop_w = [x[0] for x in stop_ww]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(cv.vocabulary_.items())[1451:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(cv.vocabulary_.items(), reverse=True)[552:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Подготовка наборов данных\n",
    "    - Разобьем датасет на два фолда: для тренировки (0000 - 36137) и предсказания (36138 - 41137)\n",
    "    - Из фолдов удалим строки в которых нет ключевых слов сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выделение набора df_train для предсказания (c известными полом и возрастом)\n",
    "df_train = df.loc[0:36137]\n",
    "df_train['raw_keywords'] = df_train['raw_keywords'].apply(lambda x: ' '.join(x))\n",
    "df_train = df_train[df_train['raw_keywords'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выделение набора df_predict для предсказания (без известных пола и возраста)\n",
    "df_predict = df.loc[36138:]\n",
    "\n",
    "# -- ??????????????????????????\n",
    "df_predict_ALL_uid = df['uid'] # все UID до удаления тех, для которых НЕ будет выполняться прогноз !!!!\n",
    "\n",
    "df_predict['raw_keywords'] = df_predict['raw_keywords'].apply(lambda x: ' '.join(x))\n",
    "df_predict = df_predict[df_predict['raw_keywords'] != '']\n",
    "\n",
    "df_predict_uid = df_predict['uid'] # все UID для которых будет выполняться прогноз !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Строим матрицу слов по объединенному массиву текстов из наборов df_train и df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_FOR_FIT = df_train.shape[0]\n",
    "ROWS_FOR_PREDICT = df_predict.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединенный массив текстов\n",
    "all_texts = pd.concat([df_train['raw_keywords'], df_predict['raw_keywords']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('data/all_texts.pickle', 'wb') as file:\n",
    "#     pickle.dump(all_texts, file) \n",
    "    \n",
    "# with open('data/all_texts.pickle', 'rb') as file:\n",
    "#     all_texts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=token_r, stop_words=stop_w)\n",
    "matrix = cv.fit_transform(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/matrix.pickle', 'wb') as file:\n",
    "#     pickle.dump(matrix, file)     \n",
    "    \n",
    "# with open('data/matrix.pickle', 'rb') as file:\n",
    "#     matrix = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATRIX_FOR_FIT = matrix[:ROWS_FOR_FIT][:]\n",
    "MATRIX_FOR_PREDICT = matrix[ROWS_FOR_FIT:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_age = df_train['age'].astype('int32')\n",
    "target_gender = df_train['gender'].astype('int32')\n",
    "df_train_uid = df_train['uid']\n",
    "df_train = df_train.drop(['age', 'gender', 'uid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssv/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    MATRIX_FOR_FIT, \n",
    "    target_gender, \n",
    "    test_size=0.33,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "    print('AUC             =====> ', metrics.auc(fpr, tpr))\n",
    "    print('accuracy_score  =====> ', metrics.accuracy_score(y_test, pred))\n",
    "    print('precision_score =====> ', metrics.precision_score(y_test, pred))\n",
    "    print('recall_score    =====> ', metrics.recall_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC             =====>  0.628039617486\n",
      "accuracy_score  =====>  0.627855153203\n",
      "precision_score =====>  0.639548022599\n",
      "recall_score    =====>  0.618579234973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty='l1')\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC             =====>  0.638363139593\n",
      "accuracy_score  =====>  0.639554317549\n",
      "precision_score =====>  0.632411067194\n",
      "recall_score    =====>  0.699453551913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=500, class_weight='balanced', random_state=0, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train) \n",
    "pred = rfc.predict(X_test)\n",
    "print_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    MATRIX_FOR_FIT, \n",
    "    target_gender, \n",
    "    test_size=0.33,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC             =====>  0.678067560854\n",
      "accuracy_score  =====>  0.677994428969\n",
      "precision_score =====>  0.687848383501\n",
      "recall_score    =====>  0.674316939891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "rfc = GradientBoostingClassifier(n_estimators=500, random_state=0)\n",
    "rfc.fit(X_train, y_train) \n",
    "pred = rfc.predict(X_test)\n",
    "print_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    MATRIX_FOR_FIT, \n",
    "    target_age, \n",
    "    test_size=0.33,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC             =====>  0.678067560854\n",
      "accuracy_score  =====>  0.677994428969\n",
      "precision_score =====>  0.687848383501\n",
      "recall_score    =====>  0.674316939891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "rfc = GradientBoostingClassifier(n_estimators=500, random_state=0)\n",
    "rfc.fit(X_train, y_train) \n",
    "pred = rfc.predict(X_test)\n",
    "print_metrics(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем на всем наборе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1500,\n",
       "              presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_gender = GradientBoostingClassifier(n_estimators=1500, random_state=0)\n",
    "rfc_gender.fit(MATRIX_FOR_FIT, target_gender) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_age = GradientBoostingClassifier(n_estimators=1500, random_state=0)\n",
    "rfc_age.fit(MATRIX_FOR_FIT, target_age) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_gender = rfc_gender.predict(MATRIX_FOR_PREDICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_age = rfc_age.predict(MATRIX_FOR_PREDICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формируем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_result = pd.DataFrame()\n",
    "pre_result['uid'] = df_predict_uid\n",
    "pre_result['gender'] = pred_gender\n",
    "pre_result['age'] = pred_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### обратная перекодировка значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genders = {1 : 'M', 0 : 'F'}\n",
    "pre_result[\"gender\"] = pre_result[\"gender\"].apply(lambda x: genders.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ages = {1 :'18-24', 2 :'25-34', 3 : '35-44', 4 : '45-54', 5 :'>=55'}\n",
    "pre_result[\"age\"] = pre_result[\"age\"].apply(lambda x: ages.get(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### слияние с полным списком uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['uid'] = df_predict_ALL_uid[36138:]\n",
    "result = pd.merge(result, pre_result, how='left', on='uid')\n",
    "result = result.fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_res = result.sort_values(by='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_res.to_csv('project01_gender-age.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns_plot = sns.pairplot(df[['url_counts', 'age']], size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 7\n",
    "sns.distplot(df['url_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['url_counts'].value_counts().head(50).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 16, 7\n",
    "sns.jointplot(df['age'], df['url_counts'], size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/df_med_keywords_non_age.pickle', 'rb') as file:\n",
    "    df_med_keywords_non_age = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_med_keywords_non_age['raw_keywords'].loc[36138:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "41138 - 5000\n",
    "\n",
    "22 + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
