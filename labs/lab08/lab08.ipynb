{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.2 (default, Sep 21 2017 18:29:43)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# SPARK_HOME=\"/Users/ssv/spark-2.2.0-bin-hadoop2.7\"\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--packages com.databricks:spark-csv_2.10:1.2.0 pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='python3'\n",
    "# os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"SPARK_HOME\"]='/Users/ssv/spark-2.2.0-bin-hadoop2.7'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.4-src.zip'))\n",
    "os.environ[\"PYSPARK_PYTHON\"] = 'python3'\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_file = 'data/u.data'\n",
    "films_file = 'data/u.item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rdd = sc.textFile(ratings_file)\n",
    "films_rdd = sc.textFile(films_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = ratings_rdd.map(lambda x: x.split('\\t')).toDF(schema=['user_id', 'film_id', 'rating', 'hz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|film_id|rating|       hz|\n",
      "+-------+-------+------+---------+\n",
      "|    196|    242|     3|881250949|\n",
      "|    186|    302|     3|891717742|\n",
      "|     22|    377|     1|878887116|\n",
      "|    244|     51|     2|880606923|\n",
      "|    166|    346|     1|886397596|\n",
      "|    298|    474|     4|884182806|\n",
      "|    115|    265|     2|881171488|\n",
      "|    253|    465|     5|891628467|\n",
      "|    305|    451|     3|886324817|\n",
      "|      6|     86|     3|883603013|\n",
      "|     62|    257|     2|879372434|\n",
      "|    286|   1014|     5|879781125|\n",
      "|    200|    222|     5|876042340|\n",
      "|    210|     40|     3|891035994|\n",
      "|    224|     29|     3|888104457|\n",
      "|    303|    785|     3|879485318|\n",
      "|    122|    387|     5|879270459|\n",
      "|    194|    274|     2|879539794|\n",
      "|    291|   1042|     4|874834944|\n",
      "|    234|   1184|     2|892079237|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_df = films_rdd.map((lambda x: (x.split('|')[0],  x.split('|')[1]))).toDF(schema=['film_id', 'film_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|film_id|           film_name|\n",
      "+-------+--------------------+\n",
      "|      1|    Toy Story (1995)|\n",
      "|      2|    GoldenEye (1995)|\n",
      "|      3|   Four Rooms (1995)|\n",
      "|      4|   Get Shorty (1995)|\n",
      "|      5|      Copycat (1995)|\n",
      "|      6|Shanghai Triad (Y...|\n",
      "|      7|Twelve Monkeys (1...|\n",
      "|      8|         Babe (1995)|\n",
      "|      9|Dead Man Walking ...|\n",
      "|     10|  Richard III (1995)|\n",
      "|     11|Seven (Se7en) (1995)|\n",
      "|     12|Usual Suspects, T...|\n",
      "|     13|Mighty Aphrodite ...|\n",
      "|     14|  Postino, Il (1994)|\n",
      "|     15|Mr. Holland's Opu...|\n",
      "|     16|French Twist (Gaz...|\n",
      "|     17|From Dusk Till Da...|\n",
      "|     18|White Balloon, Th...|\n",
      "|     19|Antonia's Line (1...|\n",
      "|     20|Angels and Insect...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df.registerTempTable(\"ratings\")\n",
    "f_df.registerTempTable(\"films\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |    films|       true|\n",
      "|        |  ratings|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_count = spark.sql(\"SELECT count(distinct(user_id)) as u_count FROM ratings\").take(1)[0].u_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_count = spark.sql(\"SELECT count(distinct(film_id)) as f_count FROM films\").take(1)[0].f_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films count = 1682, users_count = 943\n"
     ]
    }
   ],
   "source": [
    "print('films count = {}, users_count = {}'.format(films_count, users_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_user_ratings = round(spark.sql(\"SELECT count(rating) as ratings_count FROM ratings\") \\\n",
    "                                    .take(1)[0].ratings_count / users_count, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_film_ratings = round(spark.sql(\"SELECT count(rating) as ratings_count FROM ratings\") \\\n",
    "                                    .take(1)[0].ratings_count / films_count, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "completness = round(spark.sql(\"SELECT count(rating) as ratings_count FROM ratings\") \\\n",
    "                                    .take(1)[0].ratings_count / (users_count * films_count), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_film_ratings = 59.453, average_user_ratings = 106.0445, completness = 0.063\n"
     ]
    }
   ],
   "source": [
    "print('average_film_ratings = {}, average_user_ratings = {}, completness = {}'\\\n",
    "                                  .format(average_film_ratings, average_user_ratings, completness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user = spark.sql('SELECT user_id as user_id, sum(rating) as ratings_sum, count(rating) as ratings_count,' +\n",
    "                       ' ROUND (sum(rating) / count(rating), 4) as users_mean_rating FROM ratings GROUP BY user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+-----------------+\n",
      "|user_id|ratings_sum|ratings_count|users_mean_rating|\n",
      "+-------+-----------+-------------+-----------------+\n",
      "|    296|      614.0|          147|           4.1769|\n",
      "|    467|      162.0|           44|           3.6818|\n",
      "|    691|      135.0|           32|           4.2188|\n",
      "|    675|      126.0|           34|           3.7059|\n",
      "|    829|      227.0|           64|           3.5469|\n",
      "|    125|      626.0|          182|           3.4396|\n",
      "|    451|      268.0|           98|           2.7347|\n",
      "|    800|      105.0|           28|             3.75|\n",
      "|    853|      122.0|           41|           2.9756|\n",
      "|    666|      898.0|          245|           3.6653|\n",
      "|    870|      929.0|          269|           3.4535|\n",
      "|    919|      753.0|          217|             3.47|\n",
      "|    926|       66.0|           20|              3.3|\n",
      "|      7|     1598.0|          403|           3.9653|\n",
      "|    124|       84.0|           24|              3.5|\n",
      "|     51|       82.0|           23|           3.5652|\n",
      "|    447|      500.0|          139|           3.5971|\n",
      "|    591|      307.0|           84|           3.6548|\n",
      "|    307|      425.0|          112|           3.7946|\n",
      "|    475|       72.0|           20|              3.6|\n",
      "+-------+-----------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_user.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user id for ratings prediction:  94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, ratings_sum: double, ratings_count: bigint, users_mean_rating: double]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_user.corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
